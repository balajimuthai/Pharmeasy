import os
import boto3
import time
import psycopg2 as ps2
from os import path
from airflow import DAG
from airflow.operators.python_operator import PythonOperator
# from airflow.contrib.operators.qubole_operator import QuboleOperator
from airflow.models import Variable
from datetime import date
from datetime import datetime
from airflow.utils.helpers import cross_downstream
import pe_analytics_module as pam
from pe_analytics_module import update_redshift_table
from airflow.operators.sensors import ExternalTaskSensor
import requests

from io import StringIO
import pandas as pd
import email
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
from email.mime.application import MIMEApplication
import smtplib as smt
from datetime import timedelta

import sys
AIRFLOW_HOME = os.environ.get("AIRFLOW_HOME")
# sys.path.insert(0, AIRFLOW_HOME+"/dags/hive_data_models/csrd_oms/")
import pe_analytics_module as pam
from skull_mr_operator_analytics import SkullMROperatorAnalytics
sys.path.insert(0, AIRFLOW_HOME+"/dags/hive_data_models/csrd_emr/")
from dqm_function import check_table_update

dag_owner = "marketinganalytics@pharmeasy.in"
start_date = datetime(2021,8,27)
email_ids = ["marketinganalytics@pharmeasy.in"]
dag_name = "oms_customer_segmentation_raw_data_emr"
schedule_interval = '15 1 * * *' # Run every day at 6:45 AM IST 
dags_folder = "/hive_data_models"
python_version = "3.8"
dag_description = "hive Customer segementation raw data"


temp_table_list = {"install_appsflyer":['pe_consumer_af_android.installs_android_snapshot',
				 'pe_consumer_af_android.organic_installations_android_snapshot',
				 'pe_pe2_pe2.customer_appsflyer_mapping_snapshot',
				 'pe_consumer_af_ios.installs_ios_snapshot',
				 'pe_consumer_af_ios.organic_installations_ios_snapshot'],
		   "customer_data":['pe_pe2_pe2.customer_register_info_snapshot',
					 'pe_pe2_pe2.customer_snapshot'],
		   "registration_temp":['pe_pe2_pe2.customer_snapshot',
					'pe_consumer_af_android.in_app_events_android_snapshot',
					'pe_consumer_af_ios.in_app_events_ios_snapshot',
					'pe_consumer_af_android.in_app_events_retargeting_android_snapshot',
					'pe_consumer_af_ios.in_app_events_retargeting_ios_snapshot'],
		    "derived_registration_city":['pe_pe2_pe2.customer_register_info_snapshot'],
		    "latest_related_metrics":['pe_pe2_pe2.order_discount_snapshot',
					  'pe_pe2_pe2.order_Snapshot',
					  'pe_pe2_pe2.patient_snapshot',
					  'pe_pe2_pe2.medicine_notes_snapshot',
					  'pe_oms_iron.parent_order_snapshot_nrt',
					  'pe_oms_iron.parent_order_price_snapshot_snapshot_nrt',
					  'pe_oms_iron.parent_order_price_snapshot_discounts_snapshot_nrt'],	   
		   "derived_final_merge":['pe_pe2_pe2.customer_snapshot'],
		   "patient_count":['pe_pe2_pe2.rx_snapshot',
				    'pe_pe2_pe2.patient_snapshot',
				   'pe_mongo_rx.patients_snapshot_nrt']
		  }		

non_dqm_task=[ "aggregate_metrics","derived_customer_outlier","derived_ml_flags","diag_test_package","diagnosics_aggregated","final_merge","first_related_metrics",
	      "latest_overwrite","loyalty","other_aggregated_metrics","overwrite","previous_order_experience",
             "redency_dosage","referred_customer","segmention","therapy_group","total_reffered","wallet_promo"]
s3_query_folder = "csrd_emr"
query_location_on_github= AIRFLOW_HOME + "/" + "dags/hive_data_models/csrd_oms/"   


# Creating a list of default arguments for the DAG
default_args = {
                "owner" : "airflow",
                "depends_on_past" : False,
                "start_date" : start_date,
                "email" : email_ids,
                "email_on_failure" : True,
                "email_on_retry" : False,
                "qubole_connid" : "qubole_default",
                "retries" : 2,
                "retry_delay" : timedelta(minutes = 2)
               
               }
# Creating DAG object
dag = DAG(
          dag_name,
          default_args = default_args,
          description = dag_description,
          catchup = False,
          schedule_interval = schedule_interval,
          concurrency = 30
         )


# Path where SQL files are stored
folder_prefix = os.path.abspath(os.path.dirname(__file__))


# Creating an empty dictionary that will hold Qubole tasks
task = {}


for temp_table,table_list in temp_table_list.items():
    
    #file_name = open(os.path.join(folder_prefix, (temp_table + ".sql")), "r")
    task[temp_table] = SkullMROperatorAnalytics(
                          task_id = temp_table,
                          cluster_name = Variable.get("DMBI_EMR_HIVE_CLUSTER"),
                          name = temp_table,
                          arguments = None,
	    		  queue = "HIVE_queue",
                          query_location = "analytics/pe/emr_queries/" + s3_query_folder + '/',
                          filename = temp_table + ".sql",
                          query_airflow_location = query_location_on_github,
                          s3_bucket = "pe-skull-external-data",
                          dag = dag
                          )
    
    dqm_task = PythonOperator(
                          task_id = 'dqm_'+temp_table,
                          python_callable = check_table_update,
                          provide_context = True,
                          dag = dag,
                          op_kwargs = {"tables":table_list, "task_name":temp_table},
                          retry_delay=timedelta(minutes=20),
                          retries = 3
                      )
    task[temp_table] = dqm_task >> task[temp_table]



# Looping over the temp table list
# In this loop we read sql file and create Qubole objects
for temp_table in non_dqm_task:
 #file_name = open(os.path.join(folder_prefix, (temp_table + ".sql")), "r")

    task[temp_table] = SkullMROperatorAnalytics(
                          task_id = temp_table,
                          cluster_name = Variable.get("DMBI_EMR_HIVE_CLUSTER"),
                          name = temp_table,
                          arguments = None,
                          query_location = "analytics/pe/emr_queries/" + s3_query_folder + '/',
                          filename = temp_table + ".sql",
                          query_airflow_location = query_location_on_github,
                          s3_bucket = "pe-skull-external-data",
                          dag = dag
                          )
  
s3_folder_path = "s3://pe-skull-external-data/analytics/pe/hive-to-redshift-migration/csrd_oms/integrated_csrd"

iam_role = Variable.get("pe-role-analytics-password-dp")

read_from_hive ="""
select 
customer_id
,is_email_verified
,platform
,registration_time
,tenant
,chronic_intent
,acute_intent
,first_placed_order_time
,first_delivered_order_time
,first_placed_order_id
,first_delivered_order_id
,first_delivered_order_disc_percentage
,first_delivered_order_supplier_city
,fdo_disc_percentage_split
,first_power_tagged_time
,current_app_version
,current_app_os
,current_phone_details
,latest_order_rating
,latest_placed_order_time
,latest_placed_order_id
,latest_delivered_order_time
,latest_delivered_order_id
,latest_rated_order_id
,latest_delivered_order_issue_flag
,latest_order_discount
,no_of_orders
,no_of_delivered_orders
,no_of_completely_delivered_orders
,no_of_chronic_orders
,no_of_chronic_orders_delivered
,payment_mode_cod
,payment_mode_paid_via_wallet
,payment_mode_paid_online
,payment_mode_card_at_delivery
,payment_mode_cash_less_amount
,no_of_orders_cardiac
,no_of_orders_antidiabetic
,no_of_orders_vitamins_and_supplements
,no_of_orders_gastrointestinal
,no_of_orders_nervous_system
,no_of_orders_pain_management
,no_of_orders_gynaecology
,no_of_orders_respiratory
,no_of_orders_blood_related
,mrp_revenue
,discounted_revenue
,cancel_reason_cancelled_by_customer
,cancel_reason_delivery_issue
,cancel_reason_doctor_teleconsultation_issue
,cancel_reason_fake_order
,cancel_reason_medicine_issue
,cancel_reason_prescription_issue
,cancel_reason_image_issue
,cancel_reason_others
,average_order_rating
,doctor_consultation_pitched
,opted_for_doctor_consulation
,successful_doctor_consultation
,order_delivered_after_doctor_consulation
,no_of_partially_delivered_orders
,no_of_orders_dermatological
,average_mrp_order_value
,days_since_first_order
,days_since_latest_order
,days_since_latest_delivered_order
,registration_to_first_order_days
,customer_type
,customer_nps_bucket
,customer_outlier_flag
,average_order_frequency
,ml_user_type
,ml_days_since_latest_order
,ml_dormant_flag
,ml_power_customer
,is_retargeting
,adset
,site_id
,advertising_id
,is_apk
,registration_source_attribution
,no_of_diagnostic_orders
,no_of_diagnostic_fulfilled_orders
,diagnostic_gmv
,loyalty_enrolled
,loyalty_all_program_savings
,loyalty_all_program_orders
,current_loyalty_program_id
,current_loyalty_variant_id
,current_loyalty_enrollment_date
,current_loyalty_expiry_date
,current_loyalty_days_to_expiry
,current_loyalty_program_purchase_price
,current_loyalty_savings
,current_loyalty_medicine_cashback_savings
,current_loyalty_medicine_orders
,current_loyalty_doctor_consultation_eligibility
,current_loyalty_diagnostic_orders
,current_loyalty_diagnostic_savings
,wallet_balance
,promotional_cash
,transactional_cash
,total_referred_customer
,is_referred_customer
,no_of_pincodes
,no_of_unique_doctors
,therapy_group
,diagnostic_tests
,diagnostic_package
,count_of_addresses
,recent_order_source
,customer_chronic_flag
,latest_fulfilled_delivery_city
,recent_delivery_city_tier
,latest_placed_supplier_city_name
,patient_count
,preferred_payment_method
,preferred_card_option
,preferred_wallet_option
,preferred_netbanking_option
,payment_at_delivery_orders
,first_android_install_time
,latest_android_install_time
,latest_android_uninstall_time
,first_ios_install_time
,latest_ios_install_time
,install_media_source
,install_campaign
,install_source_attribution
,registration_media_source
,registration_campaign
,registration_city
,registration_state
,ideal_next_order_date_min
,ideal_next_order_date_max
,ideal_next_order_date_2_max
,ideal_next_order_date_min_chronic
,ideal_next_order_date_max_chronic
,ideal_next_order_date_2_max_chronic
,recency_segment
,recent_fm_segment
,recent_order_bucket
,recent_discount_affinity_segment
,previous_order_experience_score_change
,cast(experience_score as integer) as experience_score
,chronic_intent_date
from data_models_temp_tables.oms_customer_segmentation_raw_data_final_merge
"""
 
hive_to_s3_query = "insert overwrite directory '{s3path}/' row format delimited fields terminated by '^A' NULL DEFINED AS 'NULL' {sourcequery} --acl bucket-owner-full-control;".format(s3path = s3_folder_path, sourcequery = read_from_hive)


redshift_queries = ["DELETE FROM data_model.integrated_customer_segmentation_raw_data WHERE customer_id >= 0;",
                   "COPY data_model.integrated_customer_segmentation_raw_data FROM '{s3path}/' iam_role '{iamrole}' NULL AS 'NULL' IGNOREBLANKLINES  BLANKSASNULL REMOVEQUOTES ACCEPTINVCHARS EMPTYASNULL MAXERROR 0 DELIMITER '^' REGION 'ap-south-1' TIMEFORMAT 'YYYY-MM-DD  HH24:MI:SS' DATEFORMAT 'YYYY-MM-DD';".format(s3path = s3_folder_path, iamrole = iam_role)]
  

write_data_to_s3 = SkullMROperatorAnalytics(
                          task_id ="write_data_to_s3",
                          cluster_name = Variable.get("DMBI_EMR_HIVE_CLUSTER"),
                          name = "hive_to_s3_query",
                          arguments = hive_to_s3_query,
                          queue = "HIVE_queue",
                          query_location = "analytics/pe/emr_queries/" + s3_query_folder + '/',
                          filename = None,
                          query_airflow_location = None,
                          s3_bucket = "pe-skull-external-data",
                          dag = dag
                          ) 

redshift_execution = PythonOperator(
                                    task_id = "redshift_execution",
                                    provide_context = True,
                                    python_callable = update_redshift_table,
                                    op_kwargs={
                                               "redshift_table_update_queries" : redshift_queries                                              
                                              },
                                    dag = dag
                                   )


# sop_task = ExternalTaskSensor(task_id="sop_update_check", external_dag_id='dag_hive_sale_order_payment',
#                                   external_task_id="sop_push_to_db", execution_delta = timedelta(hours=2,minutes = 15),dag=dag,
# 			      timeout = 7200) #SOP runs at 4:30 AM IST and ends at around 4 50 A.M.


foc_task = ExternalTaskSensor(task_id="foc_update_check", external_dag_id='oms_f_order_consumer_emr',
                                  external_task_id="overwrite", execution_delta = timedelta(hours=1,minutes = 15),dag=dag,
			      timeout = 7200)


def notification():
  msg='Data model Oms_CSRD Updated successfully'
  message='{"text":"%s"}' % msg
  response=requests.post('https://hooks.slack.com/services/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',data=message)
  print(response)
	
slack_alert = PythonOperator(
                          task_id = 'Slack_notification',
                          python_callable = notification,
                          op_kwargs={},
                         dag = dag
                   )


# task_sensor------------------------------------------------

# cross_downstream([sop_task],
#                  [task["aggregate_temp"],
#                   task["latest_related_temp"],
# #                   task["master_therapy"],
#                   task["segmentation"]])

cross_downstream([foc_task],
                 [task["aggregate_metrics"],
                  task["first_related_metrics"],
                  task["latest_related_metrics"],
                  task["other_aggregated_metrics"],
                  task["previous_order_experience"],
                  task["segmention"],
                  task["therapy_group"]])


# ----------------------------------------------
  
cross_downstream([task["customer_data"]],
                 [
# 			 task["derived_reffered"],
                  task["registration_temp"],
                  task["derived_ml_flags"]])
                  
                  
task["latest_related_metrics"] >> task["latest_overwrite"]


cross_downstream([task["latest_overwrite"],task["first_related_metrics"],task["aggregate_metrics"]],[task["derived_customer_outlier"]])

cross_downstream([task["first_related_metrics"],task["customer_data"]],[task["derived_registration_city"]])
                                                                                                                                                    
cross_downstream([task["first_related_metrics"],
                  task["latest_overwrite"],
                  task["aggregate_metrics"],
                  task["customer_data"],
                  task["derived_customer_outlier"],
                  task["derived_ml_flags"],
                  task["derived_registration_city"]
                 ],[task["derived_final_merge"]])   
                                                                                                                                                                                                                                                                                                               
cross_downstream([task["customer_data"],
                  task["first_related_metrics"],
                  task["latest_overwrite"],
                  task["aggregate_metrics"],
                  task["loyalty"],
                  task["derived_final_merge"],
                  task["diagnosics_aggregated"],
                  task["patient_count"],
                  task["total_reffered"],
                  task["referred_customer"],
                  task["wallet_promo"],
                  task["other_aggregated_metrics"],
                  task["install_appsflyer"],
                  task["registration_temp"],
                  task["diag_test_package"],
                  task["therapy_group"],
                  task["segmention"],
                  task["previous_order_experience"],
		              task["redency_dosage"]],[task["final_merge"]])

task["final_merge"] >> task["overwrite"] >> slack_alert

task["final_merge"] >> write_data_to_s3 >> redshift_execution
